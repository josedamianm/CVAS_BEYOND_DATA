# CVAS Beyond Data - Complete AI Context

> **Last Updated**: 2025-01-19

---

## ğŸ“‹ Project Overview

**CVAS Beyond Data** is a production-grade ETL pipeline for telecommunications subscription data processing and analytics. It automates the daily collection of 6 transaction types (ACT, RENO, DCT, CNR, RFND, PPD) from remote PostgreSQL servers, transforms them into optimized Parquet columnar format, and builds comprehensive lifecycle views for business analytics.

### What It Does
- **Extracts** daily transaction data from remote Nova PostgreSQL server
- **Transforms** 6 transaction types into Parquet format with Hive partitioning
- **Loads** aggregated subscription views and transaction counters
- **Generates** service-level and CPC-level analytics

### How It Works
- **4-Stage Sequential Pipeline**: User Base â†’ Fetch â†’ Process â†’ Counters
- **Automated Execution**: Runs via macOS launchd scheduler (8:05 AM - 9:30 AM)
- **Data Storage**: Parquet files with Hive partitioning (`year_month=YYYY-MM`)
- **Aggregation**: DuckDB for high-performance SQL aggregation

### Performance
- **Daily Processing**: ~1.5 hours for full pipeline
- **Historical Data**: 1123+ user base snapshots
- **Transaction Volume**: Millions of records per month
- **Counter Generation**: Service and CPC-level daily aggregates

### Platform
- **OS**: macOS (launchd scheduler)
- **Python**: 3.x with Polars, DuckDB
- **Database**: PostgreSQL (remote Nova server)
- **Storage**: Parquet (SNAPPY compression)

---

## ğŸ—ï¸ Architecture Overview

### 4-Stage Sequential Pipeline

```
1.GET_NBS_BASE.sh (8:05 AM)
    â†“ Fetches user base snapshot from Nova
2.FETCH_DAILY_DATA.sh (8:25 AM)
    â†“ Fetches 6 transaction types (ACT, RENO, DCT, CNR, RFND, PPD)
3.PROCESS_DAILY_AND_BUILD_VIEW.sh (8:30 AM)
    â†“ Converts CSVs to Parquet, builds subscription view
4.BUILD_TRANSACTION_COUNTERS.sh (9:30 AM)
    â†“ Generates service and CPC-level counters (INDEPENDENT)
```

**CRITICAL**: Stages 1-3 MUST run sequentially. Stage 4 is independent but requires Stage 3 completion.

### Technology Stack
- **Python**: Polars (data processing), DuckDB (aggregation)
- **Shell**: Bash scripts for orchestration
- **Storage**: Parquet with Hive partitioning
- **Scheduler**: macOS launchd
- **Database**: PostgreSQL (remote Nova server)

### Directory Structure
```
CVAS_BEYOND_DATA/
â”œâ”€â”€ 1.GET_NBS_BASE.sh                    # Stage 1: Fetch user base
â”œâ”€â”€ 2.FETCH_DAILY_DATA.sh                # Stage 2: Fetch transactions
â”œâ”€â”€ 3.PROCESS_DAILY_AND_BUILD_VIEW.sh    # Stage 3: Process & aggregate
â”œâ”€â”€ 4.BUILD_TRANSACTION_COUNTERS.sh      # Stage 4: Build counters
â”œâ”€â”€ Scripts/
â”‚   â”œâ”€â”€ 01_aggregate_user_base.py        # User base aggregation
â”‚   â”œâ”€â”€ 02_fetch_remote_nova_data.sh     # Remote data fetching
â”‚   â”œâ”€â”€ 03_process_daily.py              # Daily CSV to Parquet
â”‚   â”œâ”€â”€ 04_build_subscription_view.py    # Subscription lifecycle view
â”‚   â”œâ”€â”€ 05_build_counters.py             # Counter generation
â”‚   â”œâ”€â”€ 00_convert_historical.py         # Historical CSV to Parquet
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ counter_utils.py             # Counter utilities
â”‚       â””â”€â”€ log_rotation.sh              # Log management
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ build_subscription_view.sql      # DuckDB aggregation query
â”œâ”€â”€ Daily_Data/                          # Daily CSV files (gitignored)
â”œâ”€â”€ Parquet_Data/                        # Parquet storage (gitignored)
â”‚   â””â”€â”€ transactions/
â”‚       â”œâ”€â”€ act/year_month=*/
â”‚       â”œâ”€â”€ reno/year_month=*/
â”‚       â”œâ”€â”€ dct/year_month=*/
â”‚       â”œâ”€â”€ cnr/year_month=*/
â”‚       â”œâ”€â”€ rfnd/year_month=*/
â”‚       â””â”€â”€ ppd/year_month=*/
â”œâ”€â”€ User_Base/                           # User base snapshots (gitignored)
â”œâ”€â”€ Counters/                            # Counter outputs (gitignored)
â”‚   â”œâ”€â”€ Counters_CPC.parquet
â”‚   â””â”€â”€ Counters_Service.csv
â””â”€â”€ Logs/                                # Pipeline logs (gitignored)
```

---

## ğŸš¨ CRITICAL ARCHITECTURE CONSTRAINTS (NON-NEGOTIABLE)

### 1. Sequential Pipeline Dependency (NEVER BREAK)
**RULE**: Scripts MUST execute in strict order. Each depends on the previous completing successfully.

```
1.GET_NBS_BASE.sh â†’ 2.FETCH_DAILY_DATA.sh â†’ 3.PROCESS_DAILY_AND_BUILD_VIEW.sh â†’ 4.BUILD_TRANSACTION_COUNTERS.sh
```

**Why**: Script 2 needs yesterday's data. Script 3 needs all 6 transaction CSV files from Script 2. Script 4 needs Parquet transaction data from Script 3.

**DO NOT**:
- âŒ Make scripts independent
- âŒ Add parallel execution
- âŒ Remove dependency validation
- âŒ Change execution order

**DO**:
- âœ… Validate previous stage completed before starting
- âœ… Log dependencies clearly
- âœ… Exit with error if prerequisites missing

### 2. Six Transaction Types (NEVER CHANGE COUNT)
**RULE**: Exactly 6 transaction types must be processed. Adding/removing types breaks the entire pipeline.

```
ACT, RENO, DCT, CNR, RFND, PPD
```

**Why**: DuckDB aggregation query expects all 6. Missing types cause SQL failures.

### 3. Directory Structure (IMMUTABLE)
**RULE**: Never modify the directory structure. Scripts use relative paths from project root.

### 4. Strict Schema Enforcement (NON-NEGOTIABLE)
**RULE**: All Parquet files must follow exact schemas. Schema violations cause aggregation failures.

### 5. Hive Partitioning (REQUIRED FOR PERFORMANCE)
**RULE**: All transaction Parquet files MUST use Hive partitioning by `year_month=YYYY-MM`.

### 6. Absolute Python Path (LAUNCHD REQUIREMENT)
**RULE**: All Python scripts called from launchd MUST use absolute path: `/opt/anaconda3/bin/python`

### 7. No PII in Logs (SECURITY)
**RULE**: NEVER log `tmuserid` or `msisdn` in automated processes. Only in manual debugging.

---

## ğŸ”§ Recent Fixes & Changes

### 1. âœ… Refund Count Logic Fixed (Jan 18, 2026)
**Issue**: `rfnd_count` was counting rows instead of summing the `rfnd_cnt` column, causing undercounting.

**Root Cause**:
- `rfnd_atlas.csv` contains aggregated refund data where one row can represent multiple refunds
- The `rfnd_cnt` column stores the actual number of refunds per row
- Previous logic: `len(rfnd_df)` â†’ counted rows
- Correct logic: `rfnd_df['rfnd_cnt'].sum()` â†’ sums actual refund counts

**Files Modified**:
- `Scripts/05_build_counters.py:compute_daily_cpc_counts()` - Changed aggregation logic
- `Scripts/utils/counter_utils.py:load_transactions_for_date()` - Ensured `rfnd_cnt` column is loaded

**Validation**:
- Beauty & Health Dec 2025: **7,001 refunds** (was 737) âœ…
- Amount: **â‚¬15,033.93** (was â‚¬8,959.41) âœ…

### 2. âœ… Parquet Data Regeneration (Jan 18, 2026)
**Issue**: `Parquet_Data/transactions/rfnd` was outdated and missing 436 rows for Dec 2025.

**Root Cause**:
- Historical conversion script `Scripts/00_convert_historical.py` hadn't been run after recent `rfnd_atlas.csv` updates
- Parquet files were stale compared to source CSVs

**Solution**:
- Re-ran `Scripts/00_convert_historical.py` to regenerate all parquet files from `rfnd_atlas.csv`
- Verified completeness: 1,173 rows, 7,001 refunds, â‚¬15,033.93 for Beauty & Health Dec 2025 âœ…

### 3. âœ… Deactivation Count Logic (Previously Fixed)
**Issue**: `dct_count` was including upgrade deactivations, inflating the count.

**Solution**:
- Filter out `channel_dct == 'UPGRADE'` when counting deactivations
- Track upgrade deactivations separately in `upg_dct_count`

---

## ğŸ“Š Data Schemas

### Transaction Types

#### ACT/RENO/PPD (15 columns - with revenue):
```python
{
    'tmuserid': pl.Utf8,
    'msisdn': pl.Utf8,
    'cpc': pl.Int64,
    'trans_type_id': pl.Int64,
    'channel_id': pl.Int64,
    'channel_act': pl.Utf8,
    'trans_date': pl.Datetime,
    'act_date': pl.Datetime,
    'reno_date': pl.Datetime,
    'camp_name': pl.Utf8,
    'tef_prov': pl.Int64,
    'campana_medium': pl.Utf8,
    'campana_id': pl.Utf8,
    'subscription_id': pl.Int64,  # PRIMARY KEY
    'rev': pl.Float64
}
```

#### DCT (13 columns - no revenue):
```python
# Same as ACT minus 'rev', plus:
{'channel_dct': pl.Utf8}
```

#### CNR (5 columns):
```python
{
    'cancel_date': pl.Datetime,
    'sbn_id': pl.Int64,  # subscription_id
    'tmuserid': pl.Utf8,
    'cpc': pl.Int64,
    'mode': pl.Utf8
}
```

#### RFND (7 columns):
```python
{
    'tmuserid': pl.Utf8,
    'cpc': pl.Int64,
    'refnd_date': pl.Datetime,
    'rfnd_amount': pl.Float64,
    'rfnd_cnt': pl.Int64,  # CRITICAL: Sum this, don't count rows!
    'sbnid': pl.Int64,  # subscription_id
    'instant_rfnd': pl.Utf8
}
```

### Counter Schemas

#### Counters_CPC.parquet (13 columns):
```python
{
    'date': pl.Date,
    'cpc': pl.Int64,
    'act_count': pl.Int64,      # Non-upgrade activations (channel_act != 'UPGRADE')
    'act_free': pl.Int64,       # Free non-upgrade activations (rev=0, channel_act != 'UPGRADE')
    'act_pay': pl.Int64,        # Paid non-upgrade activations (rev>0, channel_act != 'UPGRADE')
    'upg_count': pl.Int64,      # Upgrade activations (channel_act == 'UPGRADE')
    'reno_count': pl.Int64,
    'dct_count': pl.Int64,
    'upg_dct_count': pl.Int64,  # Upgrade deactivations (channel_dct == 'UPGRADE')
    'cnr_count': pl.Int64,
    'ppd_count': pl.Int64,
    'rfnd_count': pl.Int64,
    'rfnd_amount': pl.Float64,
    'rev': pl.Float64,
    'last_updated': pl.Datetime
}
```

#### Counters_Service.csv (21 columns):
```
date, service_name, tme_category, cpcs, Free_CPC, Free_Period, Upgrade_CPC,
CHG_Period, CHG_Price, act_count, act_free, act_pay, upg_count, reno_count,
dct_count, upg_dct_count, cnr_count, ppd_count, rfnd_count, rfnd_amount, rev
```

---

## ğŸ—‚ï¸ Critical File Locations

### Data Sources
```
/Users/josemanco/Dropbox/BEYOND_DATA_OLD_backup/
â”œâ”€â”€ Historical_Data/
â”‚   â”œâ”€â”€ act_atlas.csv
â”‚   â”œâ”€â”€ rfnd_atlas.csv      â† Primary refund source (historical)
â”‚   â”œâ”€â”€ cnr_atlas.csv
â”‚   â”œâ”€â”€ reno_atlas.csv
â”‚   â”œâ”€â”€ dct_atlas.csv
â”‚   â””â”€â”€ ppd_atlas.csv
â””â”€â”€ Daily_Data/
    â”œâ”€â”€ act_atlas_day.csv
    â”œâ”€â”€ rfnd_atlas_day.csv   â† Daily refund updates
    â””â”€â”€ ... (other daily CSVs)
```

### Processing Scripts
```
CVAS_BEYOND_DATA/
â”œâ”€â”€ Scripts/
â”‚   â”œâ”€â”€ 00_convert_historical.py    â† Converts CSVs to Parquet (run when source CSVs update)
â”‚   â”œâ”€â”€ 05_build_counters.py        â† Builds transaction counters (fixed rfnd_count logic)
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ counter_utils.py        â† Utility functions (fixed rfnd_cnt loading)
```

### Output Data
```
CVAS_BEYOND_DATA/
â”œâ”€â”€ Parquet_Data/
â”‚   â””â”€â”€ transactions/
â”‚       â”œâ”€â”€ rfnd/year_month=*/      â† Regenerated Jan 18, 2026
â”‚       â”œâ”€â”€ act/year_month=*/
â”‚       â””â”€â”€ ... (other transaction types)
â””â”€â”€ Counters/
    â”œâ”€â”€ Counters_Service.csv        â† Service-level counters (rebuilt Jan 18, 2026)
    â””â”€â”€ Counters_CPC.parquet        â† CPC-level counters
```

---

## ğŸš€ Quick Start Commands

### Daily Pipeline Execution
```bash
# Automated via launchd (8:05 AM - 9:30 AM)
./1.GET_NBS_BASE.sh          # 8:05 AM
./2.FETCH_DAILY_DATA.sh      # 8:25 AM
./3.PROCESS_DAILY_AND_BUILD_VIEW.sh  # 8:30 AM
./4.BUILD_TRANSACTION_COUNTERS.sh    # 9:30 AM (independent)
```

### Manual Execution
```bash
# Run full pipeline manually
cd /Users/josemanco/CVAS/CVAS_BEYOND_DATA
./1.GET_NBS_BASE.sh && ./2.FETCH_DAILY_DATA.sh && ./3.PROCESS_DAILY_AND_BUILD_VIEW.sh && ./4.BUILD_TRANSACTION_COUNTERS.sh
```

### Historical Data Regeneration
```bash
# When source CSVs update
cd /Users/josemanco/CVAS/CVAS_BEYOND_DATA
/opt/anaconda3/bin/python Scripts/00_convert_historical.py

# Rebuild counters with backfill
./4.BUILD_TRANSACTION_COUNTERS.sh --backfill --force
```

### Validation Queries
```python
# Check refund counts for Beauty & Health (Dec 2025)
import polars as pl

counters = pl.read_csv('Counters/Counters_Service.csv')
beauty_health = counters.filter(
    (pl.col('tme_category').str.contains('(?i)beauty')) &
    (pl.col('date').str.starts_with('2025-12'))
)
summary = beauty_health.select([
    pl.col('rfnd_count').sum(),  # Should be 7,001
    pl.col('rfnd_amount').sum()  # Should be â‚¬15,033.93
])
```

---

## ğŸ› Troubleshooting

### Issue: Counters don't match manual counts
**Symptoms**: `rfnd_count` or `rfnd_amount` differs from manual CSV aggregation

**Checklist**:
1. âœ… Is `rfnd_cnt` being summed (not row count)?
2. âœ… Are parquet files up to date with source CSVs?
3. âœ… Has `Scripts/00_convert_historical.py` been run recently?
4. âœ… Are deactivations excluding upgrades (`channel_dct != 'UPGRADE'`)?

**Solution**:
```bash
# Regenerate parquet files
cd /Users/josemanco/CVAS/CVAS_BEYOND_DATA
/opt/anaconda3/bin/python Scripts/00_convert_historical.py

# Rebuild counters
./4.BUILD_TRANSACTION_COUNTERS.sh --backfill --force
```

### Issue: Missing data in parquet files
**Symptoms**: Parquet row count < CSV row count

**Root Cause**: Historical conversion script not run after CSV updates

**Solution**: Re-run `Scripts/00_convert_historical.py`

### Issue: Pipeline stage fails
**Symptoms**: Stage 2, 3, or 4 exits with error

**Checklist**:
1. âœ… Did previous stage complete successfully?
2. âœ… Check logs in `Logs/` directory
3. âœ… Verify data files exist in expected locations
4. âœ… Check Python path is `/opt/anaconda3/bin/python`

---

## ğŸ“ Session History

> **ğŸ¤– AI ASSISTANT**: When user says "Update documentation before closing", add a new session entry below.

### Session: Jan 19, 2025 - Documentation Consolidation
**Changes Made**:
- Consolidated CONTEXT.md, RULES.md, WARP.md into single `.ai-context.md`
- Created new README.md with mandatory AI instructions
- Deleted old documentation files (CONTEXT.md, RULES.md, WARP.md)
- Implemented 2-file structure: README.md (orchestrator) + .ai-context.md (complete context)

**Files Modified**:
- Created `.ai-context.md` - Complete project context
- Rewrote `README.md` - Mandatory AI instructions + GitHub overview
- Deleted `CONTEXT.md`, `RULES.md`, `WARP.md`

**Validation**:
- Final structure verified: 2 files only
- All critical content preserved
- AI orchestration protocol implemented

### Session: Jan 28, 2025 - AI Documentation Instructions Enhancement
**Changes Made**:
- Rewrote AI assistant instructions in `README.md` to be more explicit and forceful
- Added `â›” STOP - DO NOT PROCEED` command at the top
- Added numbered mandatory steps with table for reading all 3 documentation files
- Added checklist of required understanding before proceeding
- Added consequences warning for skipping documentation files
- Added SESSION MANAGEMENT COMMANDS section with start/end session workflows

**Files Modified**:
- `README.md` - Complete rewrite of AI instructions header, added session management commands
- `CONTEXT.md` - Added file indicator, session notes template, session commands reference
- `RULES.md` - Added file indicator with cross-reference to other docs

**Validation**:
- Instructions tested and confirmed to be more explicit and actionable
- Cross-references between all 3 files ensure models follow complete flow

### Session: Jan 18, 2026 - Refund Count Fix
**Changes Made**:
- `rfnd_count` was undercounting by ~90% for Beauty & Health
- Parquet files were outdated (missing 436 rows for Dec 2025)
- Changed `rfnd_count` logic to sum `rfnd_cnt` column
- Regenerated all parquet files from source CSVs
- Rebuilt all counters with `--backfill --force`

**Files Modified**:
- `Scripts/05_build_counters.py`
- `Scripts/utils/counter_utils.py`

**Validation**:
- Beauty & Health Dec 2025: 7,001 refunds, â‚¬15,033.93 âœ…
- All categories match manual counts âœ…

---

## ğŸ”§ Open Issues

> **ğŸ¤– AI ASSISTANT**: Update this section when new issues are discovered or resolved.

### None Currently

---

## ğŸ“š Key Concepts

### Transaction Types
- **ACT**: Activations (new subscriptions)
- **RENO**: Renewals (subscription renewals)
- **DCT**: Deactivations (subscription cancellations)
- **CNR**: Cancellations (user-initiated cancellations)
- **RFND**: Refunds (refund transactions)
- **PPD**: Prepaid (prepaid transactions)

### Counter Definitions
- **act_count**: Non-upgrade activations (excludes `channel_act='UPGRADE'`)
- **act_free**: Free non-upgrade activations (`rev=0`, `channel_act != 'UPGRADE'`)
- **act_pay**: Paid non-upgrade activations (`rev>0`, `channel_act != 'UPGRADE'`)
- **upg_count**: Upgrade activations (`channel_act == 'UPGRADE'`)
- **upg_dct_count**: Upgrade deactivations (`channel_dct == 'UPGRADE'`)
- **dct_count**: Regular deactivations (excludes upgrades)

### Service Categories
```
Beauty & Health â†’ Beauty and Health (in MASTERCPC.csv)
Education & Images â†’ Education
Free Time â†’ Free Time
Games & Ugames â†’ Games
KIDS â†’ Kids
Light â†’ Light
Music â†’ Music
News & Sport â†’ News, Sport
```

### Critical Formulas
- **Refund Count**: `rfnd_df['rfnd_cnt'].sum()` (NOT `len(rfnd_df)`)
- **Deactivation Count**: Filter `channel_dct != 'UPGRADE'`
- **Activation Count**: Filter `channel_act != 'UPGRADE'`

---

## ğŸ¯ Important Domain Knowledge

### Edge Cases & Pitfalls
1. **Missing activation records**: Some subscriptions start with RENO (no ACT record)
2. **CPC upgrades**: Subscriptions can change services (tracked separately)
3. **Subscription status hierarchy**: DCT > CNR > ACTIVE
4. **RFND partitioning**: `__HIVE_DEFAULT_PARTITION__` for NULL dates
5. **Launchd environment**: Minimal PATH, requires absolute Python path
6. **Parquet compression**: Always use SNAPPY

### Data Governance
- **User base category mapping**: BUSINESS logic - no changes without approval
- **NBS_BASE immutability**: 1123+ historical snapshots
- **PII protection**: SECURITY - no logging `tmuserid` or `msisdn` in automated processes
- **Git ignore enforcement**: NEVER commit data files

---

## ğŸ“– Validation & Metrics

### December 2025 Validation Results

#### Beauty & Health Counters (Verified Jan 18, 2026)
| Metric | Value | Status |
|--------|-------|--------|
| Activations | 1,390 | âœ… |
| Renewals | 121,973 | âœ… |
| Deactivations | 1,815 | âœ… (excludes upgrades) |
| Refunds | **7,001** | âœ… (fixed from 737) |
| Refund Amount | **â‚¬15,033.93** | âœ… (fixed from â‚¬8,959.41) |
| Revenue | â‚¬218,243.27 | âœ… |

#### All Categories (Dec 2025)
| Category | Refunds | Amount |
|----------|---------|--------|
| Beauty & Health | 7,001 | â‚¬15,033.93 |
| Education & Images | 4,764 | â‚¬8,022.24 |
| Free Time | 17,716 | â‚¬45,693.89 |
| Games & Ugames | 4,848 | â‚¬12,852.35 |
| KIDS | 1,462 | â‚¬3,646.90 |
| Light | 2,790 | â‚¬8,220.66 |
| Music | 3,777 | â‚¬31,113.72 |
| News & Sport | 1,752 | â‚¬3,282.92 |

---

**For detailed project documentation, architecture, and GitHub overview, see `README.md`**
